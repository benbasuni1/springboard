
Linear Regression

Logistic Regression

Classification
   - Loss functions (exponential, logistic rescaled, zero_one, hinge)

Naive Bayes Theorem

SVM 

Decision Trees

Random Forest (High variance, unstable)
  - Bagging
  - Gradient Boosting
  - Neural Networks

Gradient Boosting 
  - Take any subdifferentiable loss function
  - Choose a base hypothesis space for regression
  - Choose Num of Steps
  - Choose Step Size Methodology

XG Boost
  - IDF Factor

Stochastic Gradient Boosting (mini batch method)
  - Use 50% of dataset size, bag fraction
  - faster, may help overfitting

Cat Boosting
  - Better than other algorithms 
  - 

Definitions:
  Bias vs Variance
  Low bias high variance -- trees
  high bias low variance -- linear regression
  Overfitting vs underfitting

Regulization Parameters:
  Reg_alpha  - L1 Regularization
  reg_lambda - L2 Regularization
  gamma      - L0 Regularization (dependent on # of leaves)


Tuning/Training Dataset
  - Cross Validation

